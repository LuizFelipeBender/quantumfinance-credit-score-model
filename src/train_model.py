import os
import time
import joblib
import requests
import shutil
import glob
import pandas as pd
import mlflow
import mlflow.sklearn

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OrdinalEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report

# Timer
start_time = time.time()
print("üöÄ Iniciando pipeline...")

# Configura√ß√£o do MLflow
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
EXPERIMENT_NAME = os.getenv("MLFLOW_EXPERIMENT_NAME", "QuantumFinance-CreditScore")
API_DEPLOY_HOOK = os.getenv("API_DEPLOY_HOOK", "http://localhost:8000/trigger-deploy")

mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
mlflow.set_experiment(EXPERIMENT_NAME)

# Leitura dos dados
print("üì• Lendo CSV...")
df = pd.read_csv("data/raw/train.csv", low_memory=False)
df = df[df["Credit_Score"].isin(["Good", "Standard", "Poor"])]
X = df.drop(columns=["Credit_Score", "ID", "Customer_ID", "Name", "SSN", "Month"])
y = df["Credit_Score"]

# Ajuste da coluna Type_of_Loan
if "Type_of_Loan" in X.columns:
    X["Type_of_Loan"] = X["Type_of_Loan"].fillna("Unknown").astype(str).apply(lambda x: x.split(",")[0].strip())

# Identifica√ß√£o de colunas
cat_features = X.select_dtypes(include="object").columns.tolist()
num_features = X.select_dtypes(include=["float64", "int64"]).columns.tolist()

# Redu√ß√£o de cardinalidade
for col in cat_features:
    top = X[col].value_counts().nlargest(20).index
    X[col] = X[col].where(X[col].isin(top), other="Rare")

# Pipelines
numeric_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="mean"))
])
categorical_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ordinal", OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1))
])
preprocessor = ColumnTransformer([
    ("num", numeric_transformer, num_features),
    ("cat", categorical_transformer, cat_features)
])

pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("classifier", RandomForestClassifier(n_estimators=20, random_state=42))
])

# Split e treinamento
print("‚úÇÔ∏è Split treino/teste...")
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

print("üß† Treinando modelo...")
with mlflow.start_run():
    pipeline.fit(X_train, y_train)
    preds = pipeline.predict(X_test)
    acc = accuracy_score(y_test, preds)

    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(pipeline, "model")

    model_name = "quantumfinance-credit-score-model"
    result = mlflow.register_model(f"runs:/{mlflow.active_run().info.run_id}/model", model_name)

    # Espera a transi√ß√£o de est√°gio e define como 'Production'
    from mlflow.tracking import MlflowClient
    client = MlflowClient()
    client.transition_model_version_stage(
        name=model_name,
        version=result.version,
        stage="Production",
        archive_existing_versions=True
    )

    print(f"üì¶ Modelo versionado como {model_name}, vers√£o {result.version} (Production)")
    print(f"\nüéØ Acur√°cia: {acc:.4f}")
    print("üìä Classification Report:\n", classification_report(y_test, preds))

    # Salva localmente com versionamento
    os.makedirs("models", exist_ok=True)
    versioned_path = f"models/model_v{result.version}.pkl"
    latest_path = "models/model_latest.pkl"

    joblib.dump(pipeline, versioned_path)
    print(f"üíæ Modelo salvo como {versioned_path}")

    shutil.copy(versioned_path, latest_path)
    print(f"üìã C√≥pia salva como {latest_path}")

    # Mant√©m apenas os √∫ltimos 3 modelos locais
    model_files = sorted(
        glob.glob("models/model_v*.pkl"),
        key=os.path.getmtime,
        reverse=True
    )

    for old_model in model_files[3:]:
        os.remove(old_model)
        print(f"üóëÔ∏è Modelo antigo removido: {old_model}")

    # Trigger de atualiza√ß√£o da API
    try:
        response = requests.post(API_DEPLOY_HOOK)
        print(f"üîî API notificada com status {response.status_code}")
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao notificar API: {e}")

print("‚úÖ Pipeline finalizada em %.2fs" % (time.time() - start_time))
